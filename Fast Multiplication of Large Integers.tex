\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}

\fancypagestyle{plain}{%
  \fancyhf{}% Clear header/footer
  \fancyhead[L]{Computing 7, 281--292 (1971) \\ \copyright\ by Springer-Verlag 1971}%
  \renewcommand{\headrulewidth}{0pt}% No header rule
}

% Use number for \thanks footnote
\makeatletter
\let\@fnsymbol\@arabic
\makeatother

\begin{document}
\title{Fast Multiplication of Large Integers}
\author{\textbf{A.\ Schönhage,} Konstanz \\ und \\ \textbf{V.\ Strassen}, Zürich\footnote{Part of the research of the second author was done at the Departtment of Statistics, University of California, Berkeley. He wishes to thank the National Science Foundation for their support (NSF GP-7454).}}
\date{\textit{(Received on July 8, 1970)}}
\renewcommand{\thefootnote}{\arabic{footnote}}
\maketitle
\begin{center}
\textbf{Summary}
\end{center}

\textbf{Fast Multiplication of Large Numbers.} An algorithm is given for computing the product of two $N$-digit binary numbers by $O(N \lg N \lg \lg N)$. Two ways of implementing the algorithm are considered: multitape Turing machines and logical nets (with step = binary logical element.)

\section{Introduction}

The school method for multiplying two decimal numbers can be easily adapted for the multiplication of $N$-digit binary numbers using a Turing machine with multiple tapes or in a logical network (constructed from two-digit logical elements). In both cases, the computational effort is of the order of $N$. Here, we define the effort of a network as the number of its elements.

For a Turing machine that performs multiplication of numbers of arbitrary length, the effort of multiplying N-digit numbers is defined as the maximum number of head movements over all input pairs of length $N$.

The prevailing and intuitively plausible belief that the effort required by the school method cannot be significantly reduced was refuted in 1962 by A.\ Karatsuba \cite{karatsuba}, who constructed a network with
\[
O\left(N^{\lg 3}\right)
\]
elements ($\lg 3 \approx 1.58$). The method easily extends to Turing machines without difficulty.

Another surprising result was presented in the following year by Toom [7], in which a network for multiplying N-digit binary numbers with
\[
O(N 2^{\, \text{const} \sqrt{\lg N}})
\] logical elements was proposed.

Independently of Toom and using a completely different method, Schönhage \cite{schoenhage} showed in 1966 that $N$-digit numbers can be multiplied on a Turing machine with an effort of
\[
O\left(N 2^{\sqrt{2 \lg N}} (\lg N)^{3 / 2}\right)
\]

Subsequently, the Toom algorithm was also adapted to Turing machines (Cook \cite{cook2}), albeit with an increased effort of
\[
O\left(N 2^{\sqrt{2 \lg N}} (\lg N)\right)
\]
(Cook \cite{cook1} and Knuth \cite{knuth}, page 273).

The significantly different methods of Toom and Schönhage thus practically yield the same effort, which has led to speculations about its near optimality.

The interested reader is recommended to refer to Chapter 4 of Knuth's brilliant one-man encyclopedia, ``The Art of Computer Programming," where the results mentioned here are presented and proven in detail.

In this work, two methods for multiplying N-digit binary numbers are presented, which can be implemented using both logical networks and Turing machines. The effort of one method is:
\[
O(N \lg N (\lg \lg N)^{1 + \varepsilon}),
\]
whilst the effort of the other method is
\[
O(N \lg N \lg \lg N).
\]

Both methods utilize the fast Fourier transformation (Cooley and Tukey \cite{cooley}; independently, D.\ Knuth also had the idea of utilizing the fast Fourier transformation for multiplying large numbers). Its usage is suggested by the fact that the multiplication of two numbers, apart from carrying out the carries, is a convolution. Therefore, if the two binary numbers to be multiplied are arranged as strings of suitable length and these strings are interpreted as elements of a ring R, which allows for performing the necessary calculations with the strings in a faithful representation and also includes the required primitive roots of unity, the desired ``large" multiplication can be decomposed into the Fourier transformation of the two string sequences, component-wise multiplication of the transformed sequences, inverse transformation, and carrying out the carries. The resulting ``small" multiplications are treated analogously. This leads to a recursive nesting of routines of the described nature.

In our first method, we take $R = \mathbb{C}$ as the field of complex numbers, the string length is approximately $\lg N$, and we achieve an effort of $O(N \lg N(\lg \lg N)^{1 + \varepsilon})$ by nesting three times.

In our second method, we use the residue class ring $\mathbb{Z}_{F_n}$ of $\mathbb{Z}$ modulo a Fermat number $2^{2^n} + 1$, where the string length is $\approx \sqrt{N}$, and we nest approximately $\lg \lg N$ levels. The crucial advantage of Fermat numbers $F_n$ is that 2 is a primitive $2^{n+1}$-th root of unity modulo $F_n$, and its power residues have extremely simple binary representations, so the multiplication with these roots of unity is negligible.

The implementation of the second method using a logical network can be done with a depth (which determines the time complexity) of $O(\lg N)$. However, we do not go into further detail on this. The order of magnitude of $\lg N$ for the depth is naturally the best possible.

We do not believe that the order of magnitude $N \lg N \lg(\lg N)$ for the effort is optimal, but we suspect that the order of magnitude $N \lg N$ is optimal (cf. the deeper result of \cite{cook2}). Unfortunately, the online restriction for logical networks is unacceptable, and for computation on Turing machines, it is too strict in any case, as none of the mentioned methods, except for the school method, operates online).

In the next section, we introduce the fast Fourier transformation in the form we will need it later. In the third section, we outline the simpler method using $R = \mathbb{C}$, and in the fourth section, we extensively discuss the method using $R = \mathbb{Z}_{F_n}$.

\begin{thebibliography}{99}
\bibitem{cook1} Cook, S. A.: \textit{On the Minimum Computation Time of Functions.} Dissertation, Harvard University (1966).
\bibitem{cook2} Cook, S. A., and S. O. Aanderaa: \textit{On the Minimum Computation Time of Functions.} Trans. AMS 142, 291--314 (1969).
\bibitem{cooley} Cooley, J. W., and J. W. Tukey: \textit{An Algorithm for the Machine Calculation of Complex Fourier Series.} Math. Comp. 19, 297--301 (1965).
\hyphenation{Rechen-automaten}
\bibitem{karatsuba} Karatsuba, A., and J. Ofman: \textit{Multiplication of Many-Digital Numbers by Automatic Computers (Russian).} Dokl. Akad. Nauk SSSR 145, 293--294 (1962).
\bibitem{knuth} Knuth, D. E.: \textit{The Art of Computer Programming. Vol. 2: Seminumerical Algorithms, Chapter 4: Arithmetic.} Addison-Wesley, 1969.
\bibitem{schoenhage} Schönhage, A.: \textit{Multiplikation großer Zahlen.} Computing 1, 182--196 (1966).
\bibitem{toom} Toom, A. L.: \textit{The complexity of a scheme of functional elements realizing the multiplication of integers.} Dokl. Akad. Nauk SSSR 150, 496--498 (1963).
\end{thebibliography}
\end{document}